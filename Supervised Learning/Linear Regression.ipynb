{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "779e1f9b106171a7"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Linear Regression Overview\n",
    "\n",
    "In this module, we implement linear regression using the **closed-form solution** (also known as the normal equation) to estimate the probability that a tumor is malignant based on features of its cell nuclei. Although the original task is a binary classification problem (benign vs. malignant), we treat the class labels as continuous values — $0$ for benign and $1$ for malignant — and use linear regression to predict a real-valued score between $0$ and $1$.\n",
    "\n",
    "The model assumes a linear relationship between the input features $ \\mathbf{x} \\in \\mathbb{R}^d $ and the target value $ y \\in \\mathbb{R} $, defined as:\n",
    "\n",
    "$$\n",
    "\\hat{y} = \\mathbf{w}^\\top \\mathbf{x} + b\n",
    "$$\n",
    "\n",
    "To find the optimal weights $ \\mathbf{w} $ and bias $ b $, we first augment the input matrix with a column of ones to account for the bias term. We then solve for $ \\mathbf{w} $ using the normal equation:\n",
    "\n",
    "$$\n",
    "\\mathbf{w} = (X^\\top X)^{-1} X^\\top y\n",
    "$$\n",
    "\n",
    "We evaluate the model using **mean squared error (MSE)** to see how close the predicted outputs $ \\hat{y} $ are to the true labels $ y $. To interpret the results in a classification setting, we apply a threshold at $0.5$ — predictions above this value are labeled malignant ($1$), and those below are labeled benign ($0$).\n",
    "\n",
    "While this approach can provide a simple baseline, it's important to remember that linear regression isn't ideal for classification tasks, especially when the data isn't linearly separable.\n",
    "\n",
    "---\n",
    "\n",
    "## Advantages of Linear Regression\n",
    "\n",
    "- **Simple and Interpretable**: The model is easy to understand and implement, with clear relationships between inputs and outputs.\n",
    "- **Closed-Form Solution**: The normal equation provides an exact solution without the need for iterative optimization.\n",
    "- **Fast to Train**: Especially efficient on smaller datasets due to its analytical solution.\n",
    "- **Baseline for Comparison**: Serves as a strong benchmark for evaluating more complex models.\n",
    "- **Works Well with Linearly Related Data**: Performs effectively when the underlying relationship between features and target is linear.\n",
    "\n",
    "## Disadvantages of Linear Regression\n",
    "\n",
    "- **Assumes Linearity**: Poor performance if the relationship between features and target is nonlinear.\n",
    "- **Sensitive to Outliers**: Outliers can heavily influence the model's predictions and skew the results.\n",
    "- **Not Ideal for Classification**: It predicts continuous values, so thresholding is required for classification tasks, which lacks probabilistic interpretation.\n",
    "- **No Feature Interactions**: Linear regression can't capture interactions between variables unless explicitly added as new features.\n",
    "- **Collinearity Issues**: Highly correlated features can destabilize the weight estimates and reduce model reliability.\n",
    "\n",
    "---\n",
    "\n",
    "## Data Overview\n",
    "\n",
    "This project uses the **Breast Cancer Wisconsin (Diagnostic) Dataset** from the UCI Machine Learning Repository. It contains **569 samples**, each describing a breast tumor based on features extracted from a digitized image of a fine needle aspirate (FNA). Each sample includes **30 numeric features** that summarize characteristics of the cell nuclei, such as: **Radius**, **Texture**, **Perimeter**, **Area**, **Smoothness**, etc. These are reported as the **mean**, **standard error**, and **worst** values across the tumor.\n",
    "\n",
    "The target variable is **diagnosis**:\n",
    "- **M** = Malignant → encoded as **1**\n",
    "- **B** = Benign → encoded as **0**\n",
    "\n",
    "Before training, the dataset was **shuffled**, **split manually** into 80% training and 20% testing sets, and the features were **standardized** using z-score normalization.\n",
    "\n"
   ],
   "id": "120938cebac81fca"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "c0f55ad02dcc2a98"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "d5df46ae91d513a7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "51f712f28393df70"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
